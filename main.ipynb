{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Access the secret\n",
    "my_openaikey = os.getenv(\"MY_OPENAIKEY\")\n",
    "\n",
    "if not my_openaikey:\n",
    "    raise EnvironmentError(\"MY_OPENAIKEY environment variable is not set.\")\n",
    "\n",
    "# Set the OpenAI API key\n",
    "os.environ['OPENAI_API_KEY'] = my_openaikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/codespace/.python/current/lib/python3.12/site-packages (1.55.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from openai) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from openai) (2.10.2)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/codespace/.python/current/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/codespace/.python/current/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install  langchain     #Langchain\n",
    "!pip install  langchain-openai\n",
    "!pip install -U langchain-community #This contains all the document loaders\n",
    "\n",
    "!pip install -qU pypdf       #loader for pdfs\n",
    "!pip install -q faiss-gpu   #FAISS vector database and similarity of embeddings\n",
    "!pip install chromadb       #Vector database\n",
    "\n",
    "#!pip install langchain-cohere  #Use this when you need to use cohere embeddings\n",
    "\n",
    "!pip install tiktoken       #tokenizer for Open AI models\n",
    "!pip install streamlit      #GUI for apps\n",
    "!pip install PyPDF2\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A new llm function that will work with the free key provided to you\n",
    "from langchain_openai import ChatOpenAI\n",
    "def get_llm_with_free_802key(temperature, model):\n",
    "  api_key_from_kyle_and_sudhir = os.getenv(\"MY_OPENAIKEY\")\n",
    "  return ChatOpenAI(\n",
    "    api_key=api_key_from_kyle_and_sudhir,\n",
    "    base_url=\"https://api.802.mba/api/providers/openai/v1/\",\n",
    "    model_name=model,\n",
    "    temperature=temperature\n",
    "  )\n",
    "#How to call this function\n",
    "llm = get_llm_with_free_802key(temperature=0.7, model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting docchatapp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile docchatapp.py\n",
    "import os\n",
    "import streamlit as st                        # used to create our UI frontend\n",
    "\n",
    "#Libraries for Document Loaders\n",
    "#from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader # import loaders\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#Libraries for Document Splitting, embeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "#Libraries for VectorStores\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "#Chain for Q&A after retrieving external documents\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "def get_llm(temperature, model):\n",
    "  my_openaikey=os.environ['OPENAI_API_KEY']\n",
    "  return ChatOpenAI(\n",
    "    api_key=my_openaikey,\n",
    "    model_name=model,\n",
    "    temperature=temperature\n",
    "  )\n",
    "\n",
    "#A new llm function that will work with the free key provided to you\n",
    "from langchain_openai import ChatOpenAI\n",
    "def get_llm_with_free_802key_1():\n",
    "  api_key_from_kyle_and_sudhir = os.environ['OPENAI_API_KEY']\n",
    "  return ChatOpenAI(\n",
    "    api_key=api_key_from_kyle_and_sudhir,\n",
    "    #base_url=\"https://api.802.mba/api/providers/openai/v1/\",\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    "  )\n",
    "#Title for the StreamLit Page\n",
    "st.title('Auto Order')\n",
    "# Loading documents (Make sure constitution.pdf is available in the  directory)\n",
    "loader = PyPDFLoader(\"The-Grill-Dinner.pdf\")\n",
    "documents = loader.load()\n",
    "# print(documents) # print to ensure document loaded correctly.\n",
    "\n",
    "#Splitting Documents into Chunks for embeddings and the store them in vector stores\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "# to see the chunks\n",
    "# st.write(chunks[0])\n",
    "# st.write(chunks[1])\n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key=os.environ['OPENAI_API_KEY'])\n",
    "\n",
    "vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "# initialize OpenAI instance and set up a chain for Q&A from an LLM\n",
    "#llm=get_llm(temperature=0.7, model=\"gpt-3.5-turbo\")\n",
    "#llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)\n",
    "llm = get_llm_with_free_802key_1()\n",
    "\n",
    "retriever=vector_store.as_retriever()\n",
    "chain = RetrievalQA.from_chain_type(llm, retriever=retriever)\n",
    "\n",
    "\n",
    "\n",
    "# Input fields for user to enter details\n",
    "question_1 = st.text_input('How many people are dining? Reply in numbers')\n",
    "question_2 = st.text_input('What is the meal budget? Reply in High/Medium/Low')\n",
    "\n",
    "question = None\n",
    "# Generating the question string\n",
    "if question_1 and question_2:  # Ensure inputs are provided\n",
    "    question = f'Help order food for {question_1} people under a {question_2} budget.'\n",
    "\n",
    "if question:\n",
    "  # run chain\n",
    "  result = chain.invoke(question)\n",
    "  response = result['result']\n",
    "  st.write(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing local tunnel, getting the IP address, running the streamlit app, and running the app with local tunnel\n",
    "#!npm install localtunnel\n",
    "#!npm audit fix --force\n",
    "#! wget -q -O - ipv4.icanhazip.com\n",
    "#!streamlit run docchatapp.py &>/content/logs.txt\n",
    "#get_ipython().system('streamlit run docchatapp.py')\n",
    "#! npx localtunnel --port 8501"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
