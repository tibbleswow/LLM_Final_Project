{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Access the secret\n",
    "my_openaikey = os.getenv(\"MY_OPENAIKEY\")\n",
    "\n",
    "if not my_openaikey:\n",
    "    raise EnvironmentError(\"MY_OPENAIKEY environment variable is not set.\")\n",
    "\n",
    "# Set the OpenAI API key\n",
    "os.environ['OPENAI_API_KEY'] = my_openaikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade openai\n",
    "!pip install  langchain     #Langchain\n",
    "!pip install  langchain-openai\n",
    "!pip install -U langchain-community #This contains all the document loaders\n",
    "\n",
    "!pip install -qU pypdf       #loader for pdfs\n",
    "!pip install -q faiss-gpu   #FAISS vector database and similarity of embeddings\n",
    "!pip install chromadb       #Vector database\n",
    "\n",
    "#!pip install langchain-cohere  #Use this when you need to use cohere embeddings\n",
    "\n",
    "!pip install tiktoken       #tokenizer for Open AI models\n",
    "!pip install streamlit      #GUI for apps\n",
    "!pip install PyPDF2\n",
    "!pip install faiss-cpu\n",
    "!pip install BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A new llm function that will work with the free key provided to you\n",
    "from langchain_openai import ChatOpenAI\n",
    "def get_llm_with_free_802key(temperature, model):\n",
    "  api_key_from_kyle_and_sudhir = os.getenv(\"MY_OPENAIKEY\")\n",
    "  return ChatOpenAI(\n",
    "    api_key=api_key_from_kyle_and_sudhir,\n",
    "    base_url=\"https://api.802.mba/api/providers/openai/v1/\",\n",
    "    model_name=model,\n",
    "    temperature=temperature\n",
    "  )\n",
    "#How to call this function\n",
    "llm = get_llm_with_free_802key(temperature=0.7, model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting auto_order_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile auto_order_app.py\n",
    "import os\n",
    "import streamlit as st\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PyPDF2 import PdfReader\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "# Function to initialize LLM\n",
    "def get_llm_with_free_802key_1():\n",
    "    api_key = os.environ['OPENAI_API_KEY']\n",
    "    return ChatOpenAI(api_key=api_key, model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Streamlit UI\n",
    "st.title('Auto Order System')\n",
    "\n",
    "# Input: URL\n",
    "url = st.text_input(\"Enter the URL of the menu:\")\n",
    "\n",
    "\n",
    "# Input: Number of diners and budget\n",
    "question_1 = st.text_input(\"How many people are dining? Reply in numbers: \")\n",
    "question_2 = st.text_input(\"Additional requests (Optional): \")\n",
    "past_review = st.text_input(\"Input customer reviews: (Optional. \"\n",
    "                            \"For current version, we are not able to read views from websites. Please copy and paste the reviews directly below)\")\n",
    "\n",
    "# Process documents and answer questions\n",
    "if question_1 and url:\n",
    "    try:\n",
    "\n",
    "        if url:\n",
    "            try:\n",
    "                if url.lower().endswith(\".pdf\"):\n",
    "                    \n",
    "                    response = requests.get(url)\n",
    "                    pdf_filename = \"new_menu.pdf\"\n",
    "                    if response.status_code == 200:\n",
    "                        with open(pdf_filename, 'wb') as f:\n",
    "                            f.write(response.content)\n",
    "                        st.info(\"PDF processed successfully\")\n",
    "                    else:\n",
    "                        st.info(\"Failed to download PDF. Status code: {response.status_code}\")\n",
    "                        loader = None\n",
    "                    loader = PyPDFLoader(pdf_filename)\n",
    "                else:\n",
    "                    st.info(\"Scraping webpage...\")\n",
    "                    loader = WebBaseLoader(url)\n",
    "                \n",
    "                if loader:  # Ensure loader is defined\n",
    "                    documents = loader.load()\n",
    "                    if not documents:\n",
    "                        st.error(\"No documents were loaded. Please check the URL or PDF content.\")\n",
    "                    else:\n",
    "                        st.success(f\"Loaded {len(documents)} documents successfully!\")\n",
    "                        # Debugging: Print the content of the first document\n",
    "                        #st.write(\"First Document Content:\", documents[0].page_content if documents else \"No content found.\")\n",
    "                        #for i, doc in enumerate(documents):\n",
    "                        #    st.write(f\"Document {i + 1} Content:\", doc.page_content)\n",
    "                else:\n",
    "                    st.error(\"Loader could not be initialized.\")\n",
    "            except Exception as e:\n",
    "                st.error(f\"Failed to process the URL: {e}\")\n",
    "                \n",
    "        # Convert documents to LangChain format\n",
    "        # documents = [Document(page_content=doc[\"content\"], metadata={}) for doc in documents]\n",
    "\n",
    "        # Split documents into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "        #if chunks:\n",
    "        #    if len(chunks) > 0:\n",
    "        #        st.write(chunks[0])\n",
    "        #    if len(chunks) > 1:\n",
    "        #        st.write(chunks[1])\n",
    "        #else:\n",
    "        #    st.error(\"No content could be split into chunks. Please check the input document.\")\n",
    "        \n",
    "        # Create embeddings and vector store\n",
    "        embeddings = OpenAIEmbeddings(api_key=os.environ['OPENAI_API_KEY'])\n",
    "        vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "        retriever = vector_store.as_retriever()\n",
    "\n",
    "        # Initialize LLM and chain\n",
    "        llm = get_llm_with_free_802key_1()\n",
    "        chain = RetrievalQA.from_chain_type(llm, retriever=retriever)\n",
    "\n",
    "        # Construct query\n",
    "        if question_2:\n",
    "            hint  = f\"Help order food for {question_1} people. Additional requests: {question_2}\" \n",
    "            query = f\"\"\"Help order food for {question_1} people. Additional requests:{question_2}.\n",
    "                    Provide a list food based on the number of people and give a calculation of total cost before tax and tip.\"\"\"\n",
    "        else:\n",
    "            hint  = f\"Help order food for {question_1} people.\"\n",
    "            query = f\"\"\"Help order food for {question_1} people. \n",
    "            Provide a list food based on the number of people and give a calculation of total cost before tax and tip. \n",
    "            Assume no dietary restriction and normal budget requirement.\"\"\"\n",
    "        # Get response\n",
    "        if past_review:\n",
    "            query += f\"\"\" When providing dish recommendations, please refer to the following reviews: {past_review}. \"\"\"\n",
    "            hint  += f\"\"\" We are referring to the dining reviews you provided.\"\"\"\n",
    "        st.write(hint)\n",
    "        result = chain.invoke(query)\n",
    "        response = result['result']\n",
    "        st.write(response)\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error generating response: {e}\")\n",
    "else:\n",
    "    if url and (not question_1):\n",
    "        st.info(\"Please provide both the number of people.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing local tunnel, getting the IP address, running the streamlit app, and running the app with local tunnel\n",
    "#!npm install localtunnel\n",
    "#!npm audit fix --force\n",
    "#! wget -q -O - ipv4.icanhazip.com\n",
    "#!streamlit run docchatapp.py &>/content/logs.txt\n",
    "#!streamlit run auto_order_app.py &>/content/logs.txt\n",
    "#get_ipython().system('streamlit run docchatapp.py')\n",
    "#! npx localtunnel --port 8501"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
