{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Access the secret\n",
    "my_openaikey = os.getenv(\"MY_OPENAIKEY\")\n",
    "\n",
    "if not my_openaikey:\n",
    "    raise EnvironmentError(\"MY_OPENAIKEY environment variable is not set.\")\n",
    "\n",
    "# Set the OpenAI API key\n",
    "os.environ['OPENAI_API_KEY'] = my_openaikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install  langchain     #Langchain\n",
    "!pip install  langchain-openai\n",
    "!pip install -U langchain-community #This contains all the document loaders\n",
    "\n",
    "!pip install -qU pypdf       #loader for pdfs\n",
    "!pip install -q faiss-gpu   #FAISS vector database and similarity of embeddings\n",
    "!pip install chromadb       #Vector database\n",
    "\n",
    "#!pip install langchain-cohere  #Use this when you need to use cohere embeddings\n",
    "\n",
    "!pip install tiktoken       #tokenizer for Open AI models\n",
    "!pip install streamlit      #GUI for apps\n",
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A new llm function that will work with the free key provided to you\n",
    "from langchain_openai import ChatOpenAI\n",
    "def get_llm_with_free_802key(temperature, model):\n",
    "  api_key_from_kyle_and_sudhir = os.getenv(\"MY_OPENAIKEY\")\n",
    "  return ChatOpenAI(\n",
    "    api_key=api_key_from_kyle_and_sudhir,\n",
    "    base_url=\"https://api.802.mba/api/providers/openai/v1/\",\n",
    "    model_name=model,\n",
    "    temperature=temperature\n",
    "  )\n",
    "#How to call this function\n",
    "llm = get_llm_with_free_802key(temperature=0.7, model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting docchatapp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile docchatapp.py\n",
    "import os\n",
    "import streamlit as st                        # used to create our UI frontend\n",
    "\n",
    "#Libraries for Document Loaders\n",
    "#from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader # import loaders\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#Libraries for Document Splitting, embeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "#Libraries for VectorStores\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "#Chain for Q&A after retrieving external documents\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "def get_llm(temperature, model):\n",
    "  my_openaikey=os.environ['OPENAI_API_KEY']\n",
    "  return ChatOpenAI(\n",
    "    api_key=my_openaikey,\n",
    "    model_name=model,\n",
    "    temperature=temperature\n",
    "  )\n",
    "\n",
    "#A new llm function that will work with the free key provided to you\n",
    "from langchain_openai import ChatOpenAI\n",
    "def get_llm_with_free_802key_1():\n",
    "  api_key_from_kyle_and_sudhir = os.environ['OPENAI_API_KEY']\n",
    "  return ChatOpenAI(\n",
    "    api_key=api_key_from_kyle_and_sudhir,\n",
    "    base_url=\"https://api.802.mba/api/providers/openai/v1/\",\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    "  )\n",
    "#Title for the StreamLit Page\n",
    "st.title('Chat about the constitution')\n",
    "# Loading documents (Make sure constitution.pdf is available in the  directory)\n",
    "loader = PyPDFLoader(\"constitution.pdf\")\n",
    "documents = loader.load()\n",
    "# print(documents) # print to ensure document loaded correctly.\n",
    "\n",
    "#Splitting Documents into Chunks for embeddings and the store them in vector stores\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "# to see the chunks\n",
    "# st.write(chunks[0])\n",
    "# st.write(chunks[1])\n",
    "embeddings = OpenAIEmbeddings(api_key=os.environ['OPENAI_API_KEY'])\n",
    "vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "# initialize OpenAI instance and set up a chain for Q&A from an LLM\n",
    "#llm=get_llm(temperature=0.7, model=\"gpt-3.5-turbo\")\n",
    "#llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)\n",
    "llm = get_llm_with_free_802key_1()\n",
    "\n",
    "retriever=vector_store.as_retriever()\n",
    "chain = RetrievalQA.from_chain_type(llm, retriever=retriever)\n",
    "\n",
    "\n",
    "# get question from user input using streamlit interface\n",
    "#Example question: \"What are the three branches of government?\"\n",
    "question = st.text_input('Input your question:')\n",
    "if question:\n",
    "  # run chain\n",
    "  result = chain.invoke(question)\n",
    "  response = result['result']\n",
    "  st.write(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\n",
      "up to date, audited 23 packages in 583ms\n",
      "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\n",
      "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K3 packages are looking for funding\n",
      "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K  run `npm fund` for details\n",
      "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\n",
      "2 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerabilities\n",
      "\n",
      "To address all issues (including breaking changes), run:\n",
      "  npm audit fix --force\n",
      "\n",
      "Run `npm audit` for details.\n",
      "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94musing --force\u001b[39m Recommended protections disabled.\n",
      "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94maudit\u001b[39m Updating localtunnel to 1.8.3, which is a SemVer major change.\n",
      "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m cryptiles@2.0.5: This version has been deprecated in accordance with the hapi support policy (hapi.im/support). Please upgrade to the latest version to get the best features, bug fixes, and security patches. If you are unable to upgrade at this time, paid support is available for older versions (hapi.im/commercial).\n",
      "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m boom@2.10.1: This version has been deprecated in accordance with the hapi support policy (hapi.im/support). Please upgrade to the latest version to get the best features, bug fixes, and security patches. If you are unable to upgrade at this time, paid support is available for older versions (hapi.im/commercial).\n",
      "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m sntp@1.0.9: This module moved to @hapi/sntp. Please make sure to switch over as this distribution is no longer supported and may contain bugs and critical security issues.\n",
      "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m uuid@3.4.0: Please upgrade  to version 7 or higher.  Older versions may use Math.random() in certain circumstances, which is known to be problematic.  See https://v8.dev/blog/math-random for details.\n",
      "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m hoek@2.16.3: This version has been deprecated in accordance with the hapi support policy (hapi.im/support). Please upgrade to the latest version to get the best features, bug fixes, and security patches. If you are unable to upgrade at this time, paid support is available for older versions (hapi.im/commercial).\n",
      "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m request@2.81.0: request has been deprecated, see https://github.com/request/request/issues/3142\n",
      "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m har-validator@4.2.1: this library is no longer supported\n",
      "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m hawk@3.1.3: This module moved to @hapi/hawk. Please make sure to switch over as this distribution is no longer supported and may contain bugs and critical security issues.\n",
      "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
      "added 78 packages, removed 10 packages, changed 11 packages, and audited 91 packages in 5s\n",
      "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
      "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K11 packages are looking for funding\n",
      "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K  run `npm fund` for details\n",
      "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
      "\u001b[1m# npm audit report\u001b[22m\n",
      "\n",
      "\u001b[1majv\u001b[22m  <6.12.3\n",
      "Severity: \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m\n",
      "\u001b[1mPrototype Pollution in Ajv\u001b[22m - https://github.com/advisories/GHSA-v88g-cgmw-v5xw\n",
      "\u001b[32m\u001b[1mfix available\u001b[22m\u001b[39m via `npm audit fix`\n",
      "\u001b[2mnode_modules/ajv\u001b[22m\n",
      "  \u001b[1mhar-validator\u001b[22m  3.3.0 - 5.1.0\n",
      "  Depends on vulnerable versions of \u001b[1majv\u001b[22m\n",
      "  \u001b[2mnode_modules/har-validator\u001b[22m\n",
      "    \u001b[1mrequest\u001b[22m  *\n",
      "    Depends on vulnerable versions of \u001b[1mhar-validator\u001b[22m\n",
      "    Depends on vulnerable versions of \u001b[1mhawk\u001b[22m\n",
      "    Depends on vulnerable versions of \u001b[1mtough-cookie\u001b[22m\n",
      "    \u001b[2mnode_modules/request\u001b[22m\n",
      "      \u001b[1mlocaltunnel\u001b[22m  <=1.9.0\n",
      "      Depends on vulnerable versions of \u001b[1mdebug\u001b[22m\n",
      "      Depends on vulnerable versions of \u001b[1mrequest\u001b[22m\n",
      "      \u001b[2mnode_modules/localtunnel\u001b[22m\n",
      "\n",
      "\u001b[1mdebug\u001b[22m  <=2.6.8\n",
      "Severity: \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m\n",
      "\u001b[1mdebug Inefficient Regular Expression Complexity vulnerability\u001b[22m - https://github.com/advisories/GHSA-9vvw-cc9w-f27h\n",
      "\u001b[1mRegular Expression Denial of Service in debug\u001b[22m - https://github.com/advisories/GHSA-gxpj-cx7g-858c\n",
      "\u001b[32m\u001b[1mfix available\u001b[22m\u001b[39m via `npm audit fix`\n",
      "\u001b[2mnode_modules/debug\u001b[22m\n",
      "\n",
      "\u001b[1mhawk\u001b[22m  <=9.0.0\n",
      "Severity: \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m\n",
      "\u001b[1mUncontrolled Resource Consumption in Hawk\u001b[22m - https://github.com/advisories/GHSA-44pw-h2cw-w3vq\n",
      "Depends on vulnerable versions of \u001b[1mboom\u001b[22m\n",
      "Depends on vulnerable versions of \u001b[1mcryptiles\u001b[22m\n",
      "Depends on vulnerable versions of \u001b[1mhoek\u001b[22m\n",
      "Depends on vulnerable versions of \u001b[1msntp\u001b[22m\n",
      "\u001b[32m\u001b[1mfix available\u001b[22m\u001b[39m via `npm audit fix`\n",
      "\u001b[2mnode_modules/hawk\u001b[22m\n",
      "\n",
      "\u001b[1mhoek\u001b[22m  *\n",
      "Severity: \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m\n",
      "\u001b[1mPrototype Pollution in hoek\u001b[22m - https://github.com/advisories/GHSA-jp4x-w63m-7wgm\n",
      "\u001b[1mhoek subject to prototype pollution via the clone function.\u001b[22m - https://github.com/advisories/GHSA-c429-5p7v-vgjp\n",
      "\u001b[32m\u001b[1mfix available\u001b[22m\u001b[39m via `npm audit fix`\n",
      "\u001b[2mnode_modules/hoek\u001b[22m\n",
      "  \u001b[1mboom\u001b[22m  <=3.1.2\n",
      "  Depends on vulnerable versions of \u001b[1mhoek\u001b[22m\n",
      "  \u001b[2mnode_modules/boom\u001b[22m\n",
      "    \u001b[1mcryptiles\u001b[22m  <=2.0.5\n",
      "    Depends on vulnerable versions of \u001b[1mboom\u001b[22m\n",
      "    \u001b[2mnode_modules/cryptiles\u001b[22m\n",
      "  \u001b[1msntp\u001b[22m  0.0.0 || 0.1.1 - 2.0.0\n",
      "  Depends on vulnerable versions of \u001b[1mhoek\u001b[22m\n",
      "  \u001b[2mnode_modules/sntp\u001b[22m\n",
      "\n",
      "\n",
      "\u001b[1mtough-cookie\u001b[22m  <4.1.3\n",
      "Severity: \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m\n",
      "\u001b[1mtough-cookie Prototype Pollution vulnerability\u001b[22m - https://github.com/advisories/GHSA-72xf-g2v4-qvf3\n",
      "\u001b[32m\u001b[1mfix available\u001b[22m\u001b[39m via `npm audit fix`\n",
      "\u001b[2mnode_modules/tough-cookie\u001b[22m\n",
      "\n",
      "\u001b[31m\u001b[1m11\u001b[22m\u001b[39m vulnerabilities (3 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m, 8 \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m)\n",
      "\n",
      "To address all issues, run:\n",
      "  npm audit fix\n",
      "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K20.42.11.23\n",
      "/bin/bash: /content/logs.txt: No such file or directory\n",
      "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://tall-glasses-call.loca.lt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "#Installing local tunnel, getting the IP address, running the streamlit app, and running the app with local tunnel\n",
    "!npm install localtunnel\n",
    "!npm audit fix --force\n",
    "! wget -q -O - ipv4.icanhazip.com\n",
    "!streamlit run docchatapp.py &>/content/logs.txt\n",
    "#get_ipython().system('streamlit run docchatapp.py')\n",
    "! npx localtunnel --port 8501"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
